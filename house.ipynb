{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "sEJMjlLG-RCs",
        "outputId": "79f9ea6b-cb4f-4d0e-a754-491c518e2fd0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'SalePrice'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'SalePrice'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2b3cd1c154e0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# EDA – DISTRIBUIÇÃO DE SALEPRICE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SalePrice'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkde\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Distribuição Original de SalePrice'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'SalePrice'"
          ]
        }
      ],
      "source": [
        "# ----------------------------\n",
        "# IMPORTAÇÃO E CONFIGURAÇÕES\n",
        "# ----------------------------\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from scipy.stats import skew\n",
        "from scipy.special import boxcox1p\n",
        "\n",
        "from sklearn.linear_model import Lasso, ElasticNet\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set(style=\"darkgrid\")\n",
        "%matplotlib inline\n",
        "\n",
        "# ----------------------------\n",
        "# LEITURA DOS DADOS\n",
        "# ----------------------------\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "y_train = train_df['SalePrice']\n",
        "train_ID = train_df['Id']\n",
        "test_ID = test_df['Id']\n",
        "train_df.drop(['SalePrice'], axis=1, inplace=True)\n",
        "\n",
        "all_data = pd.concat([train_df, test_df], axis=0).reset_index(drop=True)\n",
        "\n",
        "# ----------------------------\n",
        "# EDA – DISTRIBUIÇÃO DE SALEPRICE\n",
        "# ----------------------------\n",
        "sns.histplot(train_df['SalePrice'], kde=True)\n",
        "plt.title('Distribuição Original de SalePrice')\n",
        "plt.show()\n",
        "print(f\"SKewness: {train_df['SalePrice'].skew()}\")\n",
        "print(f\"SKewness: {train_df['SalePrice'].kurt()}\")\n",
        "\n",
        "correlation_matrix = train_df.corr(numeric_only=True)\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm')\n",
        "plt.show()\n",
        "print(correlation_matrix['SalePrice'].sort_values(ascending=False).head(15))\n",
        "\n",
        "# Exemplo com OverallQual\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x= 'OverallQual', y='SalePrice', data=train_df)\n",
        "plt.title('SalePrice vs OverallQual')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x=train_df['GrLivArea'], y=train_df['SalePrice'])\n",
        "plt.title('GrLivArea vs SalePrice')\n",
        "plt.show()\n",
        "\n",
        "total_missing = train_df.isnull().sum().sort_values(ascending=False)\n",
        "percent_missing = (train_df.isnull().sum() / train_df.isnull().count()).sort_values(ascending=False)\n",
        "\n",
        "missing_data = pd.concat([total_missing, percent_missing], axis=1, keys=['Total', 'Percentual'])\n",
        "print(missing_data[missing_data['Total'] > 0])\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(train_df.isnull(), cbar=False, yticklabels=False, cmap='viridis')\n",
        "plt.title('Visualização de Dados Faltantes no Treino')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Train Dataset\n",
        "total_missing_train = train_df.isnull().sum().sort_values(ascending=False)\n",
        "percent_missing_train = (train_df.isnull().sum() / train_df.isnull().count()).sort_values(ascending=False)\n",
        "\n",
        "missing_data_train = pd.concat([total_missing_train, percent_missing_train], axis=1, keys=['Total', 'Percentual'])\n",
        "print(\"Dados faltantes no conjunto de treino:\")\n",
        "print(missing_data_train[missing_data_train['Total'] > 0])\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(train_df.isnull(), cbar=False, yticklabels=False, cmap='viridis')\n",
        "plt.title('Visualização de Dados Faltantes no Treino')\n",
        "plt.show()\n",
        "\n",
        "# Test Dataset\n",
        "total_missing_test = test_df.isnull().sum().sort_values(ascending=False)\n",
        "percent_missing_test = (test_df.isnull().sum() / test_df.isnull().count()).sort_values(ascending=False)\n",
        "\n",
        "missing_data_test = pd.concat([total_missing_test, percent_missing_test], axis=1, keys=['Total', 'Percentual'])\n",
        "print(\"\\nDados faltantes no conjunto de teste:\")\n",
        "print(missing_data_test[missing_data_test['Total'] > 0])\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(test_df.isnull(), cbar=False, yticklabels=False, cmap='viridis')\n",
        "plt.title('Visualização de Dados Faltantes no Teste')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# TRATAMENTO DE DADOS FALTANTES\n",
        "# ----------------------------\n",
        "for col in ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu',\n",
        "            'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
        "            'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
        "            'MasVnrType']:\n",
        "    all_data[col] = all_data[col].fillna(\"None\")\n",
        "\n",
        "for col in ['GarageYrBlt', 'GarageArea', 'GarageCars',\n",
        "            'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
        "            'BsmtFullBath', 'BsmtHalfBath', 'MasVnrArea']:\n",
        "    all_data[col] = all_data[col].fillna(0)\n",
        "\n",
        "all_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
        "\n",
        "for col in ['MSZoning', 'Electrical', 'KitchenQual', 'Exterior1st', 'Exterior2nd', 'SaleType', 'Functional']:\n",
        "    all_data[col] = all_data[col].fillna(all_data[col].mode()[0])\n",
        "\n",
        "all_data = all_data.drop(['Utilities'], axis=1)\n",
        "\n",
        "# ----------------------------\n",
        "# ENCODING E TRANSFORMAÇÕES\n",
        "# ----------------------------\n",
        "num_to_cat = ['MSSubClass', 'OverallCond', 'YrSold', 'MoSold']\n",
        "for col in num_to_cat:\n",
        "    all_data[col] = all_data[col].astype(str)\n",
        "\n",
        "ord_cols = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC',\n",
        "            'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']\n",
        "for col in ord_cols:\n",
        "    lbl = LabelEncoder()\n",
        "    all_data[col] = lbl.fit_transform(all_data[col].astype(str))\n",
        "\n",
        "# ----------------------------\n",
        "# ENGENHARIA DE ATRIBUTOS\n",
        "# ----------------------------\n",
        "all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n",
        "\n",
        "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
        "skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
        "skewed = skewed_feats[abs(skewed_feats) > 0.75].index\n",
        "\n",
        "for feat in skewed:\n",
        "    all_data[feat] = boxcox1p(all_data[feat], 0.15)\n",
        "\n",
        "all_data = pd.get_dummies(all_data)\n",
        "\n",
        "# ----------------------------\n",
        "# SEPARAÇÃO DOS DADOS\n",
        "# ----------------------------\n",
        "X_train = all_data[:len(y_train)]\n",
        "X_test = all_data[len(y_train):]\n",
        "\n",
        "# ----------------------------\n",
        "# FUNÇÃO DE VALIDAÇÃO\n",
        "# ----------------------------\n",
        "def rmsle_cv(model):\n",
        "    score = -cross_val_score(model, X_train, y_train_log, scoring=\"neg_root_mean_squared_error\", cv=5)\n",
        "    return score.mean()\n",
        "\n",
        "# ----------------------------\n",
        "# MODELOS PARA COMPARAÇÃO\n",
        "# ----------------------------\n",
        "models = {\n",
        "    \"Lasso\": Lasso(alpha=0.0005, random_state=1),\n",
        "    \"ElasticNet\": ElasticNet(alpha=0.0005, l1_ratio=0.9, random_state=3),\n",
        "    \"Kernel Ridge\": KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
        "                                                    max_depth=4, max_features='sqrt',\n",
        "                                                    min_samples_leaf=15, min_samples_split=10,\n",
        "                                                    loss='huber', random_state=5),\n",
        "    \"XGBoost\": xgb.XGBRegressor(learning_rate=0.05, n_estimators=3000,\n",
        "                                max_depth=4, subsample=0.7,\n",
        "                                colsample_bytree=0.7, random_state=7),\n",
        "    \"LightGBM\": lgb.LGBMRegressor(objective='regression', num_leaves=5,\n",
        "                                  learning_rate=0.05, n_estimators=3000,\n",
        "                                  max_bin=55, bagging_fraction=0.8,\n",
        "                                  bagging_freq=5, feature_fraction=0.2319,\n",
        "                                  feature_fraction_seed=9, bagging_seed=9,\n",
        "                                  min_data_in_leaf=6, min_sum_hessian_in_leaf=11)\n",
        "}\n",
        "\n",
        "print(\"RMSLE (validação cruzada 5-fold):\")\n",
        "for name, model in models.items():\n",
        "    score = rmsle_cv(model)\n",
        "    print(f\"{name}: {score:.5f}\")\n",
        "\n",
        "# ----------------------------\n",
        "# TREINAMENTO FINAL COM MELHOR MODELO (ex: Lasso)\n",
        "# ----------------------------\n",
        "final_model = models[\"Lasso\"]\n",
        "final_model.fit(X_train, y_train_log)\n",
        "preds = np.expm1(final_model.predict(X_test))\n",
        "\n",
        "\n",
        "final_predctions = lasso_pred\n",
        "# ----------------------------\n",
        "# CRIAÇÃO DO ARQUIVO DE SUBMISSÃO\n",
        "# ----------------------------\n",
        "submission = pd.DataFrame()\n",
        "submission['Id'] = test_ID\n",
        "submission['SalePrice'] = final_predictions\n",
        "submission.to_csv('submission_house_pricess.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qPAbKO5NHVS1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}